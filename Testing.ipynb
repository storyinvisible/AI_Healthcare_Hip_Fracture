{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders import Hip_Dataset,Hip_Dataset_Specific_Path, Hip_Dataset_Selected,Hip_Dataset_One_Complete\n",
    "from PIL import Image\n",
    "import train as Train\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from Models import *\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import data_loaders\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Combined/10001502925_517424641.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Combined/10001502925_517424641.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Combined/10001083178_493490223.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Combined/10001502925_517424641.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Combined/10001541755_518066834.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            Filename  Grid\n",
       "0           0  Combined/10001502925_517424641.png     3\n",
       "1           1  Combined/10001502925_517424641.png     3\n",
       "2           2  Combined/10001083178_493490223.png     0\n",
       "3           3  Combined/10001502925_517424641.png     3\n",
       "4           4  Combined/10001541755_518066834.png     7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fracture_record=pd.read_csv(\"Fracture_record.csv\")\n",
    "image_size=(640,640)\n",
    "Fracture_record.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Batch_07/10001623568_523559394.png', 'Batch_06/10001574857_520308172.png', 'Batch_07/10001632103_524219578.png', 'datasets/10000914018_485782390.png', 'datasets/10000925240_486086363.png', 'Combined/10001226739_504239598.png', 'Batch_06/10001577733_520412474.png', 'datasets/10000921001_485910527.png', 'Combined/10001328116_511308725.png', 'Batch_07/10001608815_522630051.png', 'Batch_06/10001557255_519150117.png', 'Combined/10001502925_517424641.png', 'Batch_06/10001592839_521469374.png', 'Batch_07/10001610466_522753508.png', 'Batch_06/10001566440_519715224.png', 'Combined/10001083178_493490223.png', 'Batch_07/10001628722_524019683.png', 'Combined/10001541755_518066834.png', 'Combined/10000984194_487856846.png', 'Batch_07/10001601387_521972842.png', 'Combined/10001001739_488767941.png', 'Combined/10001272349_508125020.png', 'Combined/10001304082_509706236.png', 'Batch_06/10001563545_519545527.png'}\n"
     ]
    }
   ],
   "source": [
    "files =set(Fracture_record[\"Filename\"])\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path1 = 'Batch02/via_project_28Mar2021_16h4m_csv.csv'\n",
    "ann_path=\"datasets/via_project_19Mar2021_23h45m_csv.csv\"\n",
    "ann_path2=\"Combined/list_final.csv\"\n",
    "ann_path3=\"Batch_06/batch_06.csv\"\n",
    "ann_path4=\"Batch_07/batch_07.csv\"\n",
    "ann_path5=\"Batch_08/batch_08.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=9\n",
    "ld_test= Hip_Dataset(ann_path,\"datasets\",image_size,index)\n",
    "ld_test2=Hip_Dataset(ann_path1,\"Batch02\",image_size,index)\n",
    "\n",
    "ld_total= Hip_Dataset(ann_path2,\"Combined\",image_size,index)\n",
    "ld_06= Hip_Dataset(ann_path3,\"Batch_06\",image_size,index)\n",
    "ld_07= Hip_Dataset(ann_path4,\"Batch_07\",image_size,index)\n",
    "ld_08= Hip_Dataset(ann_path5,\"Batch_08\",image_size,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loader=ld_test+ld_total+ld_06+ld_07+ld_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11421"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=DataLoader(ld_test, batch_size =4)\n",
    "net= Custom_Net(240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for img, label in test_loader:\n",
    "    print(label.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33 14]\n",
      " [29 17]]\n"
     ]
    }
   ],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "for img, label in test_loader:\n",
    "    log_prob= net(img)[0]\n",
    "    pred= torch.argmax(log_prob).numpy()\n",
    "    y_t =label[0].numpy()\n",
    "    y_true.append(y_t)\n",
    "    y_pred.append(pred)\n",
    "    \n",
    "print(confusion_matrix(y_pred,y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fracture_record=pd.read_csv(\"Fracture_record.csv\")\n",
    "index_count =Fracture_record[\"Grid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loaders=[ld_test,ld_total,ld_06,ld_07,ld_08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fracture_df(ld_combined):\n",
    "    columns =[\"Filename\", \"Grid\"]\n",
    "    Fracture_record= pd.DataFrame(columns=columns)\n",
    "    for ld in ld_combined:\n",
    "        for k, (img, label) in enumerate(ld):\n",
    "            if label==1:\n",
    "                grid=k%9\n",
    "                file_name=ld.get_file_name(k)\n",
    "                Fracture_record=Fracture_record.append({\"Filename\":file_name,\"Grid\":grid},ignore_index = True)\n",
    "\n",
    "    return Fracture_record\n",
    "record =get_fracture_df([ld_test,ld_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=record[\"Filename\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_set =set(list(Fracture_record[\"Filename\"])+(list(filenames)))\n",
    "result = pd.concat([record, Fracture_record], axis=0)\n",
    "len(result[\"Filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=pd.DataFrame({\"Filename\" : list(files_set)})\n",
    "newdf.to_csv(\"Fracture_image.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=pd.read_csv(\"Fracture_image.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_size=(640,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322\n"
     ]
    }
   ],
   "source": [
    "ld_test =Hip_Dataset_One_Complete(ann_path,\"datasets\",image_size)\n",
    "ld_test2=Hip_Dataset_One_Complete(ann_path1,\"Batch02\",image_size)\n",
    "\n",
    "ld_total= Hip_Dataset_One_Complete(ann_path2,\"Combined\",image_size)\n",
    "ld_06= Hip_Dataset_One_Complete(ann_path3,\"Batch_06\",image_size)\n",
    "ld_07= Hip_Dataset_One_Complete(ann_path4,\"Batch_07\",image_size)\n",
    "ld_08= Hip_Dataset_One_Complete(ann_path5,\"Batch_08\",image_size)\n",
    "total_loader=ld_test2+ld_total+ld_06+ld_07+ld_08\n",
    "print(len(total_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augumentation_factor= len(total_loader)//107\n",
    "ld_test3=Hip_Dataset_Selected(\"Fracture_image.csv\",(640,640), augmentation=augumentation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_loader=total_loader+ld_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 640, 640])\n"
     ]
    }
   ],
   "source": [
    "for img, label in total_train_loader:\n",
    "    print(img.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= 10\n",
    "grid_indexes= [3,4,5,7]\n",
    "weights=np.zeros(2)\n",
    "weights=torch.FloatTensor(weights)\n",
    "weights[0]=1\n",
    "weights[1]=1\n",
    "ann_path1 = 'Batch02/via_project_28Mar2021_16h4m_csv.csv'\n",
    "ann_path=\"datasets/via_project_19Mar2021_23h45m_csv.csv\"\n",
    "ann_path2=\"Combined/list_final.csv\"\n",
    "ann_path3=\"Batch_06/batch_06.csv\"\n",
    "ann_path4=\"Batch_07/batch_07.csv\"\n",
    "ann_path5=\"Batch_08/batch_08.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(total_train_loader, batch_size = 10, shuffle = True)\n",
    "\n",
    "model,val_accuracy,val_loss_list= Train.training_setup(\"googlenet\",train_loader,ld_test2+ld_test, image_size[1],epochs,weights,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
